<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Amaia - AI Voice Chat</title>
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ¤</text></svg>">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #000; color: #fff; }
        .animate-pulse { animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useRef, useEffect } = React;

        function AmaiaPlatform() {
            const [currentPage, setCurrentPage] = useState('intro');
            const [isOnCall, setIsOnCall] = useState(false);
            const [isConnected, setIsConnected] = useState(false);
            const [status, setStatus] = useState('Amaia is online');
            const [callTranscript, setCallTranscript] = useState([]);
            const [error, setError] = useState(null);
            const [audioAllowed, setAudioAllowed] = useState(false);
            const [fallbackAudioUrl, setFallbackAudioUrl] = useState(null);
            const websocketRef = useRef(null);
            const mediaRecorderRef = useRef(null);
            const audioContext = useRef(new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 }));
            const audioQueue = useRef([]);
            const isPlaying = useRef(false);
            const recognitionRef = useRef(null);
            const pingIntervalRef = useRef(null);
            const reconnectAttempts = useRef(0);
            const maxReconnectAttempts = 5;

            // Unlock audio context
            useEffect(() => {
                const unlockAudio = () => {
                    audioContext.current.resume().then(() => {
                        console.log('Audio context unlocked');
                        setAudioAllowed(true);
                    }).catch(e => {
                        console.error('Audio unlock error:', e);
                        setError('Audio permission blocked. Click to enable.');
                    });
                };
                document.addEventListener('click', unlockAudio);
                document.addEventListener('touchstart', unlockAudio);
                return () => {
                    document.removeEventListener('click', unlockAudio);
                    document.removeEventListener('touchstart', unlockAudio);
                };
            }, []);

            // Local speech recognition for UI transcript
            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (SpeechRecognition) {
                    recognitionRef.current = new SpeechRecognition();
                    recognitionRef.current.continuous = true;
                    recognitionRef.current.interimResults = true;
                    recognitionRef.current.lang = 'en-US';

                    recognitionRef.current.onresult = (event) => {
                        let transcript = '';
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            transcript += event.results[i][0].transcript + ' ';
                        }
                        console.log('Interim transcript:', transcript);
                        if (event.results[event.results.length - 1].isFinal) {
                            const finalTranscript = event.results[event.results.length - 1][0].transcript;
                            addToTranscript('You', finalTranscript);
                        }
                    };
                    recognitionRef.current.onerror = (event) => {
                        console.error('Speech error:', event.error);
                        setError('Microphone error: ' + event.error);
                    };
                    recognitionRef.current.onend = () => {
                        console.log('Speech recognition ended');
                        if (isOnCall && isConnected) recognitionRef.current.start();
                    };
                } else {
                    setError('Speech recognition not supported.');
                }
            }, [isOnCall, isConnected]);

            const addToTranscript = (speaker, text) => {
                if (text && text.trim()) {
                    setCallTranscript(prev => [...prev, { speaker, text, time: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) }]);
                }
            };

            const createWavBuffer = (audioData) => {
                const sampleRate = 16000;
                const channels = 1;
                const bitsPerSample = 16;
                const byteRate = sampleRate * channels * (bitsPerSample / 8);
                const dataSize = audioData.byteLength;

                const buffer = new ArrayBuffer(44 + dataSize);
                const view = new DataView(buffer);

                // WAV header
                view.setUint32(0, 0x52494646, false); // "RIFF"
                view.setUint32(4, 36 + dataSize, true); // Chunk size
                view.setUint32(8, 0x57415645, false); // "WAVE"
                view.setUint32(12, 0x666d7420, false); // "fmt "
                view.setUint32(16, 16, true); // Subchunk1 size
                view.setUint16(20, 1, true); // PCM format
                view.setUint16(22, channels, true); // Channels
                view.setUint32(24, sampleRate, true); // Sample rate
                view.setUint32(28, byteRate, true); // Byte rate
                view.setUint16(32, channels * (bitsPerSample / 8), true); // Block align
                view.setUint16(34, bitsPerSample, true); // Bits per sample
                view.setUint32(36, 0x64617461, false); // "data"
                view.setUint32(40, dataSize, true); // Data size

                // Copy audio data
                const audioBytes = new Uint8Array(audioData);
                for (let i = 0; i < audioBytes.length; i++) {
                    view.setUint8(44 + i, audioBytes[i]);
                }

                return buffer;
            };

            const playAudioQueue = async () => {
                if (isPlaying.current || audioQueue.current.length === 0) return;
                isPlaying.current = true;
                const chunk = audioQueue.current.shift();
                console.log('Processing audio chunk, size:', chunk.byteLength);

                // Save chunk for debugging
                const debugBlob = new Blob([chunk], { type: 'audio/ogg' });
                const debugUrl = URL.createObjectURL(debugBlob);
                const debugLink = document.createElement('a');
                debugLink.href = debugUrl;
                debugLink.download = `agent_response_${Date.now()}.ogg`;
                debugLink.click();
                console.log('Saved audio chunk as agent_response_[timestamp].ogg');

                // Try direct Opus playback first
                try {
                    console.log('Attempting direct Opus playback...');
                    const audio = new Audio(debugUrl);
                    audio.play().then(() => {
                        console.log('Direct Opus playback started');
                        audio.onended = () => {
                            console.log('Direct Opus playback ended');
                            isPlaying.current = false;
                            playAudioQueue();
                        };
                    }).catch(err => {
                        console.error('Direct Opus playback error:', err.message);
                        throw err; // Fallback to PCM
                    });
                } catch (err) {
                    // Fallback to PCM decoding
                    try {
                        const wavBuffer = createWavBuffer(chunk);
                        console.log('Decoding WAV audio...');
                        const buffer = await audioContext.current.decodeAudioData(wavBuffer);
                        const source = audioContext.current.createBufferSource();
                        source.buffer = buffer;
                        source.connect(audioContext.current.destination);
                        source.start();
                        console.log('PCM audio playback started');
                        source.onended = () => {
                            console.log('PCM audio chunk ended');
                            isPlaying.current = false;
                            playAudioQueue();
                        };
                    } catch (pcmErr) {
                        console.error('PCM decode error:', pcmErr.message);
                        isPlaying.current = false;
                        setFallbackAudioUrl(debugUrl);
                        console.log('Set fallback audio player with URL');
                        playAudioQueue();
                    }
                }
            };

            const getSignedUrl = async () => {
                try {
                    console.log('Fetching signed URL...');
                    const response = await fetch('/api/signed-url');
                    if (!response.ok) throw new Error('Failed to get signed URL');
                    const data = await response.json();
                    console.log('Signed URL received:', data.signedUrl.slice(0, 50) + '...');
                    return data.signedUrl;
                } catch (error) {
                    console.error('Signed URL error:', error);
                    setError('Failed to connect to Amaia. Check console.');
                    return null;
                }
            };

            const startCall = async () => {
                setIsOnCall(true);
                setCurrentPage('call');
                setStatus('Connecting to Amaia...');
                setCallTranscript([{
                    speaker: 'Amaia',
                    text: "Hey, I'm so glad you called. Talk to me.",
                    time: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
                }]);
                reconnectAttempts.current = 0;
                connectWebSocket();
            };

            const connectWebSocket = async () => {
                if (reconnectAttempts.current >= maxReconnectAttempts) {
                    setError('Max reconnect attempts reached. Please try again.');
                    setStatus('Disconnected');
                    return;
                }

                const signedUrl = await getSignedUrl();
                if (!signedUrl) return;

                console.log('Connecting to WebSocket:', signedUrl);
                websocketRef.current = new WebSocket(signedUrl);

                websocketRef.current.onopen = async () => {
                    console.log('WebSocket connected');
                    setIsConnected(true);
                    setStatus('Connected! Speak to Amaia.');
                    reconnectAttempts.current = 0;
                    websocketRef.current.send(JSON.stringify({ type: 'conversation_initiation_client_data' }));

                    // Send pre-recorded "hello" Opus audio
                    try {
                        const response = await fetch('https://cdn.pixabay.com/audio/2023/08/07/audio_6c4e518693.mp3');
                        const audioData = await response.arrayBuffer();
                        const audioBlob = new Blob([audioData], { type: 'audio/ogg' });
                        websocketRef.current.send(audioBlob);
                        console.log('Sent initial hello audio, size:', audioBlob.size, 'bytes');
                    } catch (err) {
                        console.error('Failed to send initial hello audio:', err);
                    }

                    startMicrophone();
                    // Start ping
                    pingIntervalRef.current = setInterval(() => {
                        if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                            console.log('Sending ping');
                            websocketRef.current.send(JSON.stringify({ type: 'ping' }));
                        }
                    }, 3000);
                };

                websocketRef.current.onmessage = (event) => {
                    console.log('Received message, type:', typeof event.data);
                    if (typeof event.data === 'string') {
                        try {
                            const data = JSON.parse(event.data);
                            console.log('Received text:', JSON.stringify(data, null, 2));
                            if (data.type === 'agent_response' && data.agent_response_event?.agent_response) {
                                addToTranscript('Amaia', data.agent_response_event.agent_response);
                            } else if (data.type === 'agent_chat_response_part' && data.text_response_part?.text) {
                                addToTranscript('Amaia', data.text_response_part.text);
                            }
                        } catch (err) {
                            console.error('JSON parse error:', err.message);
                            console.log('Non-JSON message:', event.data);
                        }
                    } else if (event.data instanceof Blob) {
                        console.log('Received audio blob, size:', event.data.size);
                        event.data.arrayBuffer().then(buffer => {
                            audioQueue.current.push(buffer);
                            playAudioQueue();
                        }).catch(err => {
                            console.error('Audio buffer error:', err.message);
                            setError('Failed to process audio data');
                        });
                    } else {
                        console.log('Received unknown data type:', typeof event.data);
                        const debugBlob = new Blob([event.data], { type: 'application/octet-stream' });
                        const debugUrl = URL.createObjectURL(debugBlob);
                        const debugLink = document.createElement('a');
                        debugLink.href = debugUrl;
                        debugLink.download = `unknown_response_${Date.now()}.bin`;
                        debugLink.click();
                        console.log('Saved unknown data as unknown_response_[timestamp].bin');
                    }
                };

                websocketRef.current.onerror = (err) => {
                    console.error('WebSocket error:', err);
                    setError('Connection error. Attempting to reconnect...');
                };

                websocketRef.current.onclose = (event) => {
                    console.log('WebSocket closed, code:', event.code, 'reason:', event.reason || 'No reason provided');
                    setIsConnected(false);
                    setStatus('Disconnected');
                    stopMicrophone();
                    if (pingIntervalRef.current) {
                        clearInterval(pingIntervalRef.current);
                        pingIntervalRef.current = null;
                    }
                    if (isOnCall && reconnectAttempts.current < maxReconnectAttempts) {
                        reconnectAttempts.current += 1;
                        console.log(`Reconnecting WebSocket, attempt ${reconnectAttempts.current}/${maxReconnectAttempts}`);
                        setTimeout(connectWebSocket, 1000 * reconnectAttempts.current);
                    }
                };
            };

            const startMicrophone = async () => {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorderRef.current = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                    mediaRecorderRef.current.ondataavailable = (event) => {
                        if (event.data.size > 0 && websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                            if (event.data.size < 100) {
                                console.log('Skipping small audio chunk:', event.data.size, 'bytes');
                                return;
                            }
                            console.log('Sent audio chunk, size:', event.data.size, 'type:', event.data.type);
                            websocketRef.current.send(event.data);
                        } else {
                            console.log('Skipped audio chunk, size:', event.data.size, 'WebSocket state:', websocketRef.current?.readyState);
                        }
                    };
                    mediaRecorderRef.current.onstop = () => {
                        console.log('MediaRecorder stopped');
                    };
                    mediaRecorderRef.current.start(500);
                    console.log('Microphone streaming started');
                    setStatus('Listening...');
                    if (recognitionRef.current) recognitionRef.current.start();
                } catch (err) {
                    console.error('Mic error:', err);
                    setError('Microphone permission denied.');
                }
            };

            const stopMicrophone = () => {
                if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
                    mediaRecorderRef.current.stop();
                    mediaRecorderRef.current = null;
                }
                if (recognitionRef.current) recognitionRef.current.stop();
                console.log('Microphone stopped');
            };

            const endCall = () => {
                if (websocketRef.current) websocketRef.current.close();
                stopMicrophone();
                setIsOnCall(false);
                setCurrentPage('intro');
                setCallTranscript([]);
                setStatus('Amaia is online');
                setError(null);
                setFallbackAudioUrl(null);
                if (pingIntervalRef.current) {
                    clearInterval(pingIntervalRef.current);
                    pingIntervalRef.current = null;
                }
            };

            // INTRO PAGE
            if (currentPage === 'intro') {
                return (
                    <div style={{ minHeight: '100vh', background: '#000', color: '#fff', display: 'flex', alignItems: 'center', justifyContent: 'center', position: 'relative', overflow: 'hidden' }}>
                        <div style={{ position: 'absolute', inset: 0, opacity: 0.2 }}>
                            <div style={{ position: 'absolute', top: '80px', left: '40px', width: '384px', height: '384px', background: '#ec4899', borderRadius: '9999px', filter: 'blur(80px)' }} className="animate-pulse" />
                            <div style={{ position: 'absolute', bottom: '80px', right: '40px', width: '320px', height: '320px', background: '#a855f7', borderRadius: '9999px', filter: 'blur(80px)', animationDelay: '1s' }} className="animate-pulse" />
                        </div>

                        <div style={{ position: 'relative', zIndex: 10, maxWidth: '448px', padding: '24px', display: 'flex', flexDirection: 'column', gap: '32px', textAlign: 'center' }}>
                            <div style={{ display: 'flex', flexDirection: 'column', gap: '24px' }}>
                                <div style={{ width: '96px', height: '96px', margin: '0 auto', borderRadius: '9999px', background: 'linear-gradient(135deg, #ec4899, #a855f7)', boxShadow: '0 0 50px rgba(236, 72, 153, 0.5)' }} className="animate-pulse" />
                                <div>
                                    <h1 style={{ fontSize: '48px', fontWeight: 300, letterSpacing: '0.1em', marginBottom: '8px' }}>Amaia</h1>
                                    <p style={{ color: '#9ca3af', fontSize: '14px' }}>is calling...</p>
                                </div>
                            </div>

                            <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'center', gap: '8px' }}>
                                <div style={{ width: '8px', height: '8px', background: '#4ade80', borderRadius: '9999px' }} className="animate-pulse" />
                                <p style={{ fontSize: '12px', color: '#9ca3af' }}>live voice call</p>
                            </div>

                            <div style={{ display: 'flex', gap: '16px', justifyContent: 'center' }}>
                                <button onClick={startCall} style={{ padding: '16px 48px', background: '#16a34a', color: '#fff', border: 'none', borderRadius: '9999px', fontWeight: '600', cursor: 'pointer', fontSize: '16px', boxShadow: '0 0 20px rgba(22, 163, 74, 0.5)' }}>
                                    ðŸ“ž Answer
                                </button>
                            </div>

                            <p style={{ fontSize: '12px', color: '#4b5563', marginTop: '32px' }}>
                                Welcome to Amaia's world. Real voice conversation powered by ElevenLabs agent.
                            </p>
                            {error && <p style={{ color: '#dc2626', fontSize: '14px', fontWeight: 500 }}>{error}</p>}
                        </div>
                    </div>
                );
            }

            // CALL PAGE
            if (currentPage === 'call') {
                return (
                    <div style={{ minHeight: '100vh', background: 'linear-gradient(to bottom, #030712, #000)', color: '#fff', display: 'flex', flexDirection: 'column' }}>
                        <div style={{ position: 'sticky', top: 0, zIndex: 40, background: 'rgba(0, 0, 0, 0.8)', backdropFilter: 'blur(12px)', borderBottom: '1px solid #1f2937' }}>
                            <div style={{ maxWidth: '1024px', margin: '0 auto', padding: '0 16px', height: '64px', display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
                                <div style={{ textAlign: 'center', flex: 1 }}>
                                    <h2 style={{ fontWeight: 600 }}>Amaia</h2>
                                    <p style={{ fontSize: '12px', color: '#4ade80' }}>{isConnected ? 'on call' : 'connecting...'}</p>
                                </div>
                                <button onClick={endCall} style={{ background: '#dc2626', border: 'none', borderRadius: '9999px', padding: '12px', color: '#fff', cursor: 'pointer', fontSize: '20px' }}>
                                    ðŸ“ž
                                </button>
                            </div>
                        </div>

                        <div style={{ flex: 1, display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center', padding: '32px 16px', gap: '48px' }}>
                            <div style={{ position: 'relative' }}>
                                <div style={{ width: '128px', height: '128px', borderRadius: '9999px', background: 'linear-gradient(135deg, #ec4899, #a855f7)', boxShadow: '0 0 50px rgba(236, 72, 153, 0.5)', display: 'flex', alignItems: 'center', justifyContent: 'center', fontSize: '32px' }} className={isConnected ? 'animate-pulse' : ''}>
                                    ðŸŽ¤
                                </div>
                            </div>

                            <div style={{ textAlign: 'center' }}>
                                <p style={{ color: '#9ca3af', fontSize: '14px' }}>{status}</p>
                                {error && <p style={{ color: '#dc2626', fontSize: '14px', fontWeight: 500 }}>{error}</p>}
                            </div>

                            {fallbackAudioUrl && (
                                <div style={{ marginTop: '16px' }}>
                                    <p style={{ color: '#f59e0b', fontSize: '14px' }}>Audio decode failed. Use fallback player:</p>
                                    <audio controls src={fallbackAudioUrl}>
                                        Your browser does not support the audio element.
                                    </audio>
                                </div>
                            )}

                            <div style={{ maxWidth: '448px', display: 'flex', flexDirection: 'column', gap: '12px', maxHeight: '200px', overflowY: 'auto' }}>
                                {callTranscript.map((msg, i) => (
                                    <div key={i} style={{ fontSize: '14px', color: msg.speaker === 'You' ? '#fda4af' : '#d1d5db' }}>
                                        <p style={{ fontSize: '12px', color: '#4b5563', marginBottom: '4px' }}>{msg.speaker} ({msg.time})</p>
                                        <p>{msg.text}</p>
                                    </div>
                                ))}
                            </div>
                        </div>

                        <div style={{ background: 'rgba(0, 0, 0, 0.5)', borderTop: '1px solid #1f2937', padding: '24px 16px', maxHeight: '192px', overflowY: 'auto' }}>
                            <p style={{ fontSize: '12px', color: '#4b5563', textTransform: 'uppercase', letterSpacing: '0.05em', marginBottom: '16px' }}>Call History</p>
                            <div style={{ display: 'flex', flexDirection: 'column', gap: '12px' }}>
                                {callTranscript.map((msg, i) => (
                                    <div key={i} style={{ fontSize: '12px', color: msg.speaker === 'You' ? '#fda4af' : '#9ca3af' }}>
                                        <p style={{ fontWeight: 600, marginBottom: '4px' }}>{msg.speaker} ({msg.time})</p>
                                        <p>{msg.text}</p>
                                    </div>
                                ))}
                            </div>
                        </div>
                    </div>
                );
            }
        }

        ReactDOM.render(<AmaiaPlatform />, document.getElementById('root'));
    </script>
</body>
</html>
