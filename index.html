<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Amaia - AI Voice Chat</title>
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ¤</text></svg>">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #000; color: #fff; }
        .animate-pulse { animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useRef, useEffect } = React;

        function AmaiaPlatform() {
            const [currentPage, setCurrentPage] = useState('intro');
            const [isOnCall, setIsOnCall] = useState(false);
            const [isConnected, setIsConnected] = useState(false);
            const [status, setStatus] = useState('Amaia is online');
            const [callTranscript, setCallTranscript] = useState([]);
            const [error, setError] = useState(null);
            const [audioAllowed, setAudioAllowed] = useState(false);
            const [fallbackAudioUrl, setFallbackAudioUrl] = useState(null);
            const websocketRef = useRef(null);
            const audioContext = useRef(new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 }));
            const scriptProcessorRef = useRef(null);
            const mediaStreamRef = useRef(null);
            const audioQueue = useRef([]);
            const isPlaying = useRef(false);
            const recognitionRef = useRef(null);
            const pingIntervalRef = useRef(null);
            const reconnectAttempts = useRef(0);
            const maxReconnectAttempts = 3;
            const responseBuffer = useRef(''); // Buffer for aggregating delta messages

            // Unlock audio context
            useEffect(() => {
                const unlockAudio = () => {
                    audioContext.current.resume().then(() => {
                        console.log('Audio context unlocked');
                        setAudioAllowed(true);
                    }).catch(e => {
                        console.error('Audio unlock error:', e);
                        setError('Audio permission blocked. Click to enable.');
                    });
                };
                document.addEventListener('click', unlockAudio);
                document.addEventListener('touchstart', unlockAudio);
                return () => {
                    document.removeEventListener('click', unlockAudio);
                    document.removeEventListener('touchstart', unlockAudio);
                };
            }, []);

            // Local speech recognition for UI transcript
            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (SpeechRecognition) {
                    recognitionRef.current = new SpeechRecognition();
                    recognitionRef.current.continuous = true;
                    recognitionRef.current.interimResults = true;
                    recognitionRef.current.lang = 'en-US';

                    recognitionRef.current.onresult = (event) => {
                        let transcript = '';
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            transcript += event.results[i][0].transcript + ' ';
                        }
                        console.log('Interim transcript:', transcript);
                        if (event.results[event.results.length - 1].isFinal) {
                            const finalTranscript = event.results[event.results.length - 1][0].transcript;
                            addToTranscript('You', finalTranscript);
                        }
                    };
                    recognitionRef.current.onerror = (event) => {
                        console.error('Speech error:', event.error);
                        setError('Microphone error: ' + event.error);
                    };
                    recognitionRef.current.onend = () => {
                        console.log('Speech recognition ended');
                        if (isOnCall && isConnected) recognitionRef.current.start();
                    };
                } else {
                    setError('Speech recognition not supported.');
                }
            }, [isOnCall, isConnected]);

            const addToTranscript = (speaker, text) => {
                if (text && text.trim()) {
                    setCallTranscript(prev => [...prev, { speaker, text, time: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) }]);
                }
            };

            const playAudioQueue = async () => {
                if (isPlaying.current || audioQueue.current.length === 0) return;
                isPlaying.current = true;
                const chunk = audioQueue.current.shift();
                console.log('Processing audio chunk, size:', chunk.byteLength);

                try {
                    const buffer = await audioContext.current.decodeAudioData(chunk);
                    const source = audioContext.current.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioContext.current.destination);
                    source.start();
                    console.log('Audio playback started');
                    source.onended = () => {
                        console.log('Audio chunk ended');
                        isPlaying.current = false;
                        playAudioQueue();
                    };
                } catch (err) {
                    console.error('Audio decode error:', err.message);
                    isPlaying.current = false;
                    const blob = new Blob([chunk], { type: 'audio/wav' });
                    const url = URL.createObjectURL(blob);
                    setFallbackAudioUrl(url);
                    console.log('Fallback audio URL:', url);
                    playAudioQueue();
                }
            };

            const getSignedUrl = async () => {
                try {
                    console.log('Fetching signed URL...');
                    const response = await fetch('/api/signed-url');
                    if (!response.ok) throw new Error(`Failed to get signed URL: ${response.status}`);
                    const data = await response.json();
                    console.log('Signed URL received:', data.signedUrl.slice(0, 50) + '...');
                    return data.signedUrl;
                } catch (error) {
                    console.error('Signed URL error:', error);
                    setError('Failed to connect to Amaia. Check console.');
                    return null;
                }
            };

            const startCall = async () => {
                setIsOnCall(true);
                setCurrentPage('call');
                setStatus('Connecting to Amaia...');
                setCallTranscript([{
                    speaker: 'Amaia',
                    text: "Hey, I'm so glad you called. Talk to me.",
                    time: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
                }]);
                reconnectAttempts.current = 0;
                connectWebSocket();
            };

            const connectWebSocket = async () => {
                if (reconnectAttempts.current >= maxReconnectAttempts) {
                    setError('Max reconnect attempts reached. Please try again.');
                    setStatus('Disconnected');
                    return;
                }

                const signedUrl = await getSignedUrl();
                if (!signedUrl) return;

                console.log('Connecting to WebSocket:', signedUrl);
                websocketRef.current = new WebSocket(signedUrl);

                websocketRef.current.onopen = () => {
                    console.log('WebSocket connected');
                    setIsConnected(true);
                    setStatus('Connected! Speak to Amaia.');
                    reconnectAttempts.current = 0;
                    websocketRef.current.send(JSON.stringify({ type: 'conversation_initiation_client_data' }));
                    startMicrophone();
                    // Start ping
                    pingIntervalRef.current = setInterval(() => {
                        if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                            console.log('Sending ping');
                            websocketRef.current.send(JSON.stringify({ type: 'ping' }));
                        }
                    }, 3000);
                };

                websocketRef.current.onmessage = (event) => {
                    console.log('Received message, type:', typeof event.data);
                    if (typeof event.data === 'string') {
                        try {
                            const data = JSON.parse(event.data);
                            console.log('Received text:', JSON.stringify(data, null, 2));
                            if (data.type === 'agent_response' && data.agent_response_event?.agent_response) {
                                // Add complete response to transcript and clear buffer
                                addToTranscript('Amaia', data.agent_response_event.agent_response);
                                responseBuffer.current = '';
                            } else if (data.type === 'agent_chat_response_part' && data.text_response_part) {
                                if (data.text_response_part.type === 'start') {
                                    responseBuffer.current = ''; // Reset buffer
                                } else if (data.text_response_part.type === 'delta' && data.text_response_part.text) {
                                    responseBuffer.current += data.text_response_part.text; // Append to buffer
                                } else if (data.text_response_part.type === 'stop' && responseBuffer.current) {
                                    addToTranscript('Amaia', responseBuffer.current); // Add buffered response
                                    responseBuffer.current = '';
                                }
                            } else if (data.type === 'audio_event' && data.audio_event?.audio_base_64) {
                                console.log('Received audio event, base64 length:', data.audio_event.audio_base_64.length);
                                try {
                                    const audioBytes = Uint8Array.from(atob(data.audio_event.audio_base_64), c => c.charCodeAt(0));
                                    const buffer = new ArrayBuffer(audioBytes.length);
                                    const view = new Uint8Array(buffer);
                                    for (let i = 0; i < audioBytes.length; i++) {
                                        view[i] = audioBytes[i];
                                    }
                                    const audioBuffer = audioContext.current.createBuffer(1, audioBytes.length / 2, 16000);
                                    const floatArray = new Float32Array(audioBuffer.length);
                                    for (let i = 0; i < audioBytes.length / 2; i++) {
                                        const sample = (audioBytes[i * 2] | (audioBytes[i * 2 + 1] << 8)) / 32768;
                                        floatArray[i] = sample;
                                    }
                                    audioBuffer.getChannelData(0).set(floatArray);
                                    audioQueue.current.push(audioBuffer.buffer);
                                    console.log('Audio buffer queued, size:', audioBuffer.buffer.byteLength);
                                    playAudioQueue();
                                } catch (err) {
                                    console.error('Audio processing error:', err.message);
                                    setError('Failed to process audio response');
                                }
                            } else if (data.type === 'error') {
                                console.error('Server error:', data.error);
                                setError(`Server error: ${data.error.message || 'Unknown error'}`);
                            } else {
                                console.log('Unhandled message type:', data.type);
                            }
                        } catch (err) {
                            console.error('JSON parse error:', err.message);
                            setError('Failed to parse server response');
                        }
                    } else {
                        console.error('Received unexpected binary data');
                        setError('Received invalid data from server');
                    }
                };

                websocketRef.current.onerror = (err) => {
                    console.error('WebSocket error:', err);
                    setError('Connection error. Attempting to reconnect...');
                };

                websocketRef.current.onclose = (event) => {
                    console.log('WebSocket closed, code:', event.code, 'reason:', event.reason || 'No reason provided');
                    setIsConnected(false);
                    setStatus('Disconnected');
                    stopMicrophone();
                    if (pingIntervalRef.current) {
                        clearInterval(pingIntervalRef.current);
                        pingIntervalRef.current = null;
                    }
                    if (isOnCall && reconnectAttempts.current < maxReconnectAttempts) {
                        reconnectAttempts.current += 1;
                        console.log(`Reconnecting WebSocket, attempt ${reconnectAttempts.current}/${maxReconnectAttempts}`);
                        setTimeout(connectWebSocket, 2000 * reconnectAttempts.current);
                    }
                };
            };

            const startMicrophone = async () => {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaStreamRef.current = stream;
                    const source = audioContext.current.createMediaStreamSource(stream);
                    scriptProcessorRef.current = audioContext.current.createScriptProcessor(4096, 1, 1);
                    source.connect(scriptProcessorRef.current);
                    scriptProcessorRef.current.connect(audioContext.current.destination);
                    scriptProcessorRef.current.onaudioprocess = (e) => {
                        if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                            const input = e.inputBuffer.getChannelData(0);
                            const buffer = new ArrayBuffer(input.length * 2);
                            const view = new DataView(buffer);
                            for (let i = 0; i < input.length; i++) {
                                const s = Math.max(-1, Math.min(1, input[i]));
                                view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                            }
                            const base64 = arrayBufferToBase64(buffer);
                            websocketRef.current.send(JSON.stringify({ user_audio_chunk: base64 }));
                            console.log('Sent PCM audio chunk, size:', buffer.byteLength, 'bytes (base64 length:', base64.length, ')');
                        } else {
                            console.log('Skipped audio chunk, size:', e.inputBuffer.length * 2, 'WebSocket state:', websocketRef.current?.readyState);
                        }
                    };
                    console.log('Microphone streaming started (PCM 16000Hz)');
                    setStatus('Listening...');
                    if (recognitionRef.current) recognitionRef.current.start();
                } catch (err) {
                    console.error('Mic error:', err);
                    setError('Microphone permission denied.');
                }
            };

            const stopMicrophone = () => {
                if (mediaStreamRef.current) {
                    mediaStreamRef.current.getTracks().forEach(track => track.stop());
                    mediaStreamRef.current = null;
                }
                if (scriptProcessorRef.current) {
                    scriptProcessorRef.current.disconnect();
                    scriptProcessorRef.current = null;
                }
                if (recognitionRef.current) recognitionRef.current.stop();
                console.log('Microphone stopped');
            };

            function arrayBufferToBase64(buffer) {
                let binary = '';
                const bytes = new Uint8Array(buffer);
                const len = bytes.byteLength;
                for (let i = 0; i < len; i++) {
                    binary += String.fromCharCode(bytes[i]);
                }
                return window.btoa(binary);
            }

            const endCall = () => {
                if (websocketRef.current) websocketRef.current.close();
                stopMicrophone();
                setIsOnCall(false);
                setCurrentPage('intro');
                setCallTranscript([]);
                setStatus('Amaia is online');
                setError(null);
                setFallbackAudioUrl(null);
                if (pingIntervalRef.current) {
                    clearInterval(pingIntervalRef.current);
                    pingIntervalRef.current = null;
                }
                responseBuffer.current = '';
            };

            // INTRO PAGE
            if (currentPage === 'intro') {
                return (
                    <div style={{ minHeight: '100vh', background: '#000', color: '#fff', display: 'flex', alignItems: 'center', justifyContent: 'center', position: 'relative', overflow: 'hidden' }}>
                        <div style={{ position: 'absolute', inset: 0, opacity: 0.2 }}>
                            <div style={{ position: 'absolute', top: '80px', left: '40px', width: '384px', height: '384px', background: '#ec4899', borderRadius: '9999px', filter: 'blur(80px)' }} className="animate-pulse" />
                            <div style={{ position: 'absolute', bottom: '80px', right: '40px', width: '320px', height: '320px', background: '#a855f7', borderRadius: '9999px', filter: 'blur(80px)', animationDelay: '1s' }} className="animate-pulse" />
                        </div>

                        <div style={{ position: 'relative', zIndex: 10, maxWidth: '448px', padding: '24px', display: 'flex', flexDirection: 'column', gap: '32px', textAlign: 'center' }}>
                            <div style={{ display: 'flex', flexDirection: 'column', gap: '24px' }}>
                                <div style={{ width: '96px', height: '96px', margin: '0 auto', borderRadius: '9999px', background: 'linear-gradient(135deg, #ec4899, #a855f7)', boxShadow: '0 0 50px rgba(236, 72, 153, 0.5)' }} className="animate-pulse" />
                                <div>
                                    <h1 style={{ fontSize: '48px', fontWeight: 300, letterSpacing: '0.1em', marginBottom: '8px' }}>Amaia</h1>
                                    <p style={{ color: '#9ca3af', fontSize: '14px' }}>is calling...</p>
                                </div>
                            </div>

                            <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'center', gap: '8px' }}>
                                <div style={{ width: '8px', height: '8px', background: '#4ade80', borderRadius: '9999px' }} className="animate-pulse" />
                                <p style={{ fontSize: '12px', color: '#9ca3af' }}>live voice call</p>
                            </div>

                            <div style={{ display: 'flex', gap: '16px', justifyContent: 'center' }}>
                                <button onClick={startCall} style={{ padding: '16px 48px', background: '#16a34a', color: '#fff', border: 'none', borderRadius: '9999px', fontWeight: '600', cursor: 'pointer', fontSize: '16px', boxShadow: '0 0 20px rgba(22, 163, 74, 0.5)' }}>
                                    ðŸ“ž Answer
                                </button>
                            </div>

                            <p style={{ fontSize: '12px', color: '#4b5563', marginTop: '32px' }}>
                                Welcome to Amaia's world. Real voice conversation powered by ElevenLabs agent.
                            </p>
                            {error && <p style={{ color: '#dc2626', fontSize: '14px', fontWeight: 500 }}>{error}</p>}
                        </div>
                    </div>
                );
            }

            // CALL PAGE
            if (currentPage === 'call') {
                return (
                    <div style={{ minHeight: '100vh', background: 'linear-gradient(to bottom, #030712, #000)', color: '#fff', display: 'flex', flexDirection: 'column' }}>
                        <div style={{ position: 'sticky', top: 0, zIndex: 40, background: 'rgba(0, 0, 0, 0.8)', backdropFilter: 'blur(12px)', borderBottom: '1px solid #1f2937' }}>
                            <div style={{ maxWidth: '1024px', margin: '0 auto', padding: '0 16px', height: '64px', display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
                                <div style={{ textAlign: 'center', flex: 1 }}>
                                    <h2 style={{ fontWeight: 600 }}>Amaia</h2>
                                    <p style={{ fontSize: '12px', color: '#4ade80' }}>{isConnected ? 'on call' : 'connecting...'}</p>
                                </div>
                                <button onClick={endCall} style={{ background: '#dc2626', border: 'none', borderRadius: '9999px', padding: '12px', color: '#fff', cursor: 'pointer', fontSize: '20px' }}>
                                    ðŸ“ž
                                </button>
                            </div>
                        </div>

                        <div style={{ flex: 1, display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center', padding: '32px 16px', gap: '48px' }}>
                            <div style={{ position: 'relative' }}>
                                <div style={{ width: '128px', height: '128px', borderRadius: '9999px', background: 'linear-gradient(135deg, #ec4899, #a855f7)', boxShadow: '0 0 50px rgba(236, 72, 153, 0.5)', display: 'flex', alignItems: 'center', justifyContent: 'center', fontSize: '32px' }} className={isConnected ? 'animate-pulse' : ''}>
                                    ðŸŽ¤
                                </div>
                            </div>

                            <div style={{ textAlign: 'center' }}>
                                <p style={{ color: '#9ca3af', fontSize: '14px' }}>{status}</p>
                                {error && <p style={{ color: '#dc2626', fontSize: '14px', fontWeight: 500 }}>{error}</p>}
                            </div>

                            {fallbackAudioUrl && (
                                <div style={{ marginTop: '16px' }}>
                                    <p style={{ color: '#f59e0b', fontSize: '14px' }}>Audio decode failed. Use fallback player:</p>
                                    <audio controls src={fallbackAudioUrl}>
                                        Your browser does not support the audio element.
                                    </audio>
                                </div>
                            )}

                            <div style={{ maxWidth: '448px', display: 'flex', flexDirection: 'column', gap: '12px', maxHeight: '200px', overflowY: 'auto' }}>
                                {callTranscript.map((msg, i) => (
                                    <div key={i} style={{ fontSize: '14px', color: msg.speaker === 'You' ? '#fda4af' : '#d1d5db' }}>
                                        <p style={{ fontSize: '12px', color: '#4b5563', marginBottom: '4px' }}>{msg.speaker} ({msg.time})</p>
                                        <p>{msg.text}</p>
                                    </div>
                                ))}
                            </div>
                        </div>

                        <div style={{ background: 'rgba(0, 0, 0, 0.5)', borderTop: '1px solid #1f2937', padding: '24px 16px', maxHeight: '192px', overflowY: 'auto' }}>
                            <p style={{ fontSize: '12px', color: '#4b5563', textTransform: 'uppercase', letterSpacing: '0.05em', marginBottom: '16px' }}>Call History</p>
                            <div style={{ display: 'flex', flexDirection: 'column', gap: '12px' }}>
                                {callTranscript.map((msg, i) => (
                                    <div key={i} style={{ fontSize: '12px', color: msg.speaker === 'You' ? '#fda4af' : '#9ca3af' }}>
                                        <p style={{ fontWeight: 600, marginBottom: '4px' }}>{msg.speaker} ({msg.time})</p>
                                        <p>{msg.text}</p>
                                    </div>
                                ))}
                            </div>
                        </div>
                    </div>
                );
            }
        }

        ReactDOM.render(<AmaiaPlatform />, document.getElementById('root'));
    </script>
</body>
</html>
