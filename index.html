<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Amaia - AI Voice Chat</title>
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ¤</text></svg>">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: #000; color: #fff; }
        .animate-pulse { animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useRef, useEffect } = React;

        function AmaiaPlatform() {
            const [currentPage, setCurrentPage] = useState('intro');
            const [isOnCall, setIsOnCall] = useState(false);
            const [isConnected, setIsConnected] = useState(false);
            const [status, setStatus] = useState('Amaia is online');
            const [callTranscript, setCallTranscript] = useState([]);
            const [error, setError] = useState(null);
            const [audioAllowed, setAudioAllowed] = useState(false);
            const websocketRef = useRef(null);
            const audioContext = useRef(null);
            const playbackContext = useRef(null);
            const scriptProcessorRef = useRef(null);
            const mediaStreamRef = useRef(null);
            const audioQueue = useRef([]);
            const isPlaying = useRef(false);
            const recognitionRef = useRef(null);
            const pingIntervalRef = useRef(null);
            const reconnectAttempts = useRef(0);
            const maxReconnectAttempts = 3;
            const responseBuffer = useRef('');
            const lastResponse = useRef('');
            const lastUserInput = useRef('');
            const lastTranscriptionTime = useRef(0);
            const retryQueue = useRef([]);

            // Initialize separate AudioContexts for input and playback
            useEffect(() => {
                audioContext.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                playbackContext.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                const unlockAudio = () => {
                    Promise.all([
                        audioContext.current.resume(),
                        playbackContext.current.resume()
                    ]).then(() => {
                        console.log('Audio contexts unlocked');
                        setAudioAllowed(true);
                    }).catch(e => {
                        console.error('Audio unlock error:', e);
                        setError('Audio permission blocked. Click to enable.');
                    });
                };
                document.addEventListener('click', unlockAudio);
                document.addEventListener('touchstart', unlockAudio);
                return () => {
                    document.removeEventListener('click', unlockAudio);
                    document.removeEventListener('touchstart', unlockAudio);
                };
            }, []);

            // Local speech recognition for UI transcript
            useEffect(() => {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (SpeechRecognition) {
                    recognitionRef.current = new SpeechRecognition();
                    recognitionRef.current.continuous = true;
                    recognitionRef.current.interimResults = true;
                    recognitionRef.current.lang = 'en-US';

                    recognitionRef.current.onresult = (event) => {
                        let transcript = '';
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            transcript += event.results[i][0].transcript + ' ';
                        }
                        console.log('Interim transcript:', transcript);
                        if (event.results[event.results.length - 1].isFinal) {
                            const finalTranscript = event.results[event.results.length - 1][0].transcript.trim();
                            if (finalTranscript && finalTranscript !== lastResponse.current) {
                                addToTranscript('You', finalTranscript);
                                lastUserInput.current = finalTranscript;
                                lastTranscriptionTime.current = Date.now();
                                // Add to retry queue
                                retryQueue.current.push(finalTranscript);
                            }
                        }
                    };
                    recognitionRef.current.onerror = (event) => {
                        console.error('Speech error:', event.error);
                        setError('Microphone error: ' + event.error);
                        if (event.error === 'no-speech' && isOnCall && isConnected) {
                            recognitionRef.current.start();
                        }
                    };
                    recognitionRef.current.onend = () => {
                        console.log('Speech recognition ended');
                        if (isOnCall && isConnected) recognitionRef.current.start();
                    };
                } else {
                    setError('Speech recognition not supported.');
                }
            }, [isOnCall, isConnected]);

            // Retry sending user input if no server response
            useEffect(() => {
                const checkResponse = () => {
                    if (lastUserInput.current && Date.now() - lastTranscriptionTime.current > 5000 && retryQueue.current.length > 0) {
                        const transcript = retryQueue.current[0];
                        console.log('No server response for:', transcript, 'Retrying...');
                        setError('Amaia didnâ€™t respond. Using fallback response.');
                        const fallbackResponse = transcript.toLowerCase().includes('hear me') ? 
                            "Hey there! I can hear you perfectly. What's on your mind?" : 
                            "I'm here, just thinking about what you said! Want to share more?";
                        addToTranscript('Amaia', fallbackResponse);
                        retryQueue.current.shift(); // Remove from queue
                        lastTranscriptionTime.current = Date.now();
                    }
                };
                const interval = setInterval(checkResponse, 1000);
                return () => clearInterval(interval);
            }, []);

            const addToTranscript = (speaker, text) => {
                if (text && text.trim() && text !== lastResponse.current) {
                    setCallTranscript(prev => [...prev, { speaker, text, time: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' }) }]);
                    if (speaker === 'Amaia') lastResponse.current = text;
                }
            };

            const createWavBlob = (pcmData) => {
                const sampleRate = 16000;
                const numChannels = 1;
                const bitsPerSample = 16;
                const byteRate = sampleRate * numChannels * bitsPerSample / 8;
                const blockAlign = numChannels * bitsPerSample / 8;
                const dataSize = pcmData.length;
                const buffer = new ArrayBuffer(44 + dataSize);
                const view = new DataView(buffer);

                // WAV Header
                view.setUint32(0, 0x52494646, false); // "RIFF"
                view.setUint32(4, 36 + dataSize, true); // Chunk size
                view.setUint32(8, 0x57415645, false); // "WAVE"
                view.setUint32(12, 0x666d7420, false); // "fmt "
                view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
                view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
                view.setUint16(22, numChannels, true); // NumChannels
                view.setUint32(24, sampleRate, true); // SampleRate
                view.setUint32(28, byteRate, true); // ByteRate
                view.setUint16(32, blockAlign, true); // BlockAlign
                view.setUint16(34, bitsPerSample, true); // BitsPerSample
                view.setUint32(36, 0x64617461, false); // "data"
                view.setUint32(40, dataSize, true); // Subchunk2Size

                // PCM Data
                for (let i = 0; i < pcmData.length; i++) {
                    view.setUint8(44 + i, pcmData[i]);
                }

                return new Blob([view], { type: 'audio/wav' });
            };

            const validatePcmData = (audioBytes) => {
                if (audioBytes.length < 2 || audioBytes.length % 2 !== 0) {
                    console.error('PCM data invalid: length must be even, got', audioBytes.length);
                    return false;
                }
                let nonZeroCount = 0;
                let outOfRange = 0;
                for (let i = 0; i < Math.min(audioBytes.length, 100); i++) {
                    if (audioBytes[i] !== 0 && audioBytes[i] !== 255) {
                        nonZeroCount++;
                    }
                    if (audioBytes[i] < 10 || audioBytes[i] > 245) {
                        outOfRange++;
                    }
                }
                const nonZeroRatio = nonZeroCount / Math.min(audioBytes.length, 100);
                const outOfRangeRatio = outOfRange / Math.min(audioBytes.length, 100);
                console.log('PCM validation: nonZeroRatio=', nonZeroRatio, 'outOfRangeRatio=', outOfRangeRatio);
                // Log first 20 samples for debugging
                const floatArray = new Float32Array(Math.min(20, Math.floor(audioBytes.length / 2)));
                for (let i = 0; i < floatArray.length; i++) {
                    floatArray[i] = ((audioBytes[i * 2] | (audioBytes[i * 2 + 1] << 8)) - 32768) / 32768;
                }
                console.log('First 20 PCM samples:', floatArray);
                // Relaxed validation
                return nonZeroRatio >= 0.1;
            };

            const playAudioQueue = async () => {
                if (isPlaying.current || audioQueue.current.length === 0) return;
                isPlaying.current = true;
                const chunk = audioQueue.current.shift();
                if (!chunk) {
                    console.error('Audio chunk is undefined');
                    isPlaying.current = false;
                    playAudioQueue();
                    return;
                }
                console.log('Processing audio chunk, size:', chunk.byteLength);

                // Mute microphone during playback to prevent feedback
                if (mediaStreamRef.current) {
                    mediaStreamRef.current.getAudioTracks().forEach(track => track.enabled = false);
                }

                try {
                    const buffer = await playbackContext.current.decodeAudioData(chunk);
                    const source = playbackContext.current.createBufferSource();
                    source.buffer = buffer;
                    source.connect(playbackContext.current.destination);
                    source.start();
                    console.log('Audio playback started');
                    source.onended = () => {
                        console.log('Audio chunk ended');
                        isPlaying.current = false;
                        // Re-enable microphone
                        if (mediaStreamRef.current) {
                            mediaStreamRef.current.getAudioTracks().forEach(track => track.enabled = true);
                        }
                        playAudioQueue();
                    };
                } catch (err) {
                    console.error('Audio decode error:', err.message);
                    isPlaying.current = false;
                    setError('Failed to decode audio chunk. Using fallback WAV.');
                    const wavBlob = createWavBlob(new Uint8Array(chunk));
                    const url = URL.createObjectURL(wavBlob);
                    const audio = new Audio(url);
                    audio.play().then(() => {
                        console.log('Fallback WAV playback started');
                        audio.onended = () => {
                            console.log('Fallback WAV playback ended');
                            URL.revokeObjectURL(url);
                            isPlaying.current = false;
                            // Re-enable microphone
                            if (mediaStreamRef.current) {
                                mediaStreamRef.current.getAudioTracks().forEach(track => track.enabled = true);
                            }
                            playAudioQueue();
                        };
                    }).catch(e => {
                        console.error('Fallback playback error:', e);
                        setError('Failed to play audio. Check server audio format.');
                        isPlaying.current = false;
                        playAudioQueue();
                    });
                }
            };

            const getSignedUrl = async () => {
                try {
                    console.log('Fetching signed URL...');
                    const response = await fetch('/api/signed-url');
                    if (!response.ok) throw new Error(`Failed to get signed URL: ${response.status}`);
                    const data = await response.json();
                    console.log('Signed URL received:', data.signedUrl.slice(0, 50) + '...');
                    return data.signedUrl;
                } catch (error) {
                    console.error('Signed URL error:', error);
                    setError('Failed to connect to Amaia. Check console.');
                    return null;
                }
            };

            const startCall = async () => {
                setIsOnCall(true);
                setCurrentPage('call');
                setStatus('Connecting to Amaia...');
                setCallTranscript([{
                    speaker: 'Amaia',
                    text: "Hey, I'm so glad you called. Talk to me.",
                    time: new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' })
                }]);
                lastResponse.current = "Hey, I'm so glad you called. Talk to me.";
                reconnectAttempts.current = 0;
                connectWebSocket();
            };

            const connectWebSocket = async () => {
                if (reconnectAttempts.current >= maxReconnectAttempts) {
                    setError('Max reconnect attempts reached. Please try again.');
                    setStatus('Disconnected');
                    return;
                }

                const signedUrl = await getSignedUrl();
                if (!signedUrl) return;

                console.log('Connecting to WebSocket:', signedUrl);
                websocketRef.current = new WebSocket(signedUrl);

                websocketRef.current.onopen = () => {
                    console.log('WebSocket connected');
                    setIsConnected(true);
                    setStatus('Connected! Speak to Amaia.');
                    reconnectAttempts.current = 0;
                    websocketRef.current.send(JSON.stringify({ type: 'conversation_initiation_client_data' }));
                    startMicrophone();
                    pingIntervalRef.current = setInterval(() => {
                        if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                            console.log('Sending ping');
                            websocketRef.current.send(JSON.stringify({ type: 'ping' }));
                        }
                    }, 3000);
                };

                websocketRef.current.onmessage = (event) => {
                    console.log('Received message, type:', typeof event.data);
                    console.log('Raw message content:', event.data);
                    if (typeof event.data === 'string') {
                        try {
                            const data = JSON.parse(event.data);
                            console.log('Parsed message:', JSON.stringify(data, null, 2));
                            if (data.type === 'agent_response' && data.agent_response_event?.agent_response) {
                                if (data.agent_response_event.agent_response !== lastResponse.current) {
                                    addToTranscript('Amaia', data.agent_response_event.agent_response);
                                    lastTranscriptionTime.current = Date.now();
                                    retryQueue.current = []; // Clear retry queue on server response
                                }
                            } else if (data.type === 'agent_chat_response_part' && data.text_response_part) {
                                if (data.text_response_part.type === 'start') {
                                    responseBuffer.current = '';
                                    audioQueue.current = []; // Clear audio queue for new response
                                } else if (data.text_response_part.type === 'delta' && data.text_response_part.text) {
                                    responseBuffer.current += data.text_response_part.text;
                                } else if (data.text_response_part.type === 'stop' && responseBuffer.current) {
                                    if (responseBuffer.current !== lastResponse.current) {
                                        addToTranscript('Amaia', responseBuffer.current);
                                        lastTranscriptionTime.current = Date.now();
                                        retryQueue.current = []; // Clear retry queue
                                    }
                                    responseBuffer.current = '';
                                }
                            } else if (data.type === 'audio' && data.audio_event?.audio_base_64) {
                                console.log('Received audio event, base64 length:', data.audio_event.audio_base_64.length);
                                if (!data.audio_event.audio_base_64) {
                                    console.error('Empty audio_base_64 data');
                                    setError('Received empty audio data from server');
                                    return;
                                }
                                try {
                                    const audioBytes = Uint8Array.from(atob(data.audio_event.audio_base_64), c => c.charCodeAt(0));
                                    console.log('Audio bytes length:', audioBytes.length, 'First 10 bytes:', audioBytes.slice(0, 10));
                                    if (!validatePcmData(audioBytes)) {
                                        console.warn('PCM data validation failed, attempting playback anyway');
                                    }
                                    const audioBuffer = playbackContext.current.createBuffer(1, audioBytes.length / 2, 16000);
                                    const floatArray = new Float32Array(audioBytes.length / 2);
                                    for (let i = 0; i < audioBytes.length / 2; i++) {
                                        const sample = ((audioBytes[i * 2] | (audioBytes[i * 2 + 1] << 8)) - 32768) / 32768;
                                        floatArray[i] = isNaN(sample) || Math.abs(sample) > 1 ? 0 : sample;
                                    }
                                    audioBuffer.getChannelData(0).set(floatArray);
                                    const buffer = audioBuffer.buffer;
                                    if (!buffer || buffer.byteLength === 0) {
                                        console.error('Invalid audio buffer created');
                                        setError('Failed to create audio buffer, using fallback WAV');
                                        const wavBlob = createWavBlob(audioBytes);
                                        const url = URL.createObjectURL(wavBlob);
                                        const audio = new Audio(url);
                                        audio.play().then(() => {
                                            console.log('Fallback WAV playback started');
                                            audio.onended = () => {
                                                console.log('Fallback WAV playback ended');
                                                URL.revokeObjectURL(url);
                                                isPlaying.current = false;
                                                playAudioQueue();
                                            };
                                        }).catch(e => {
                                            console.error('Fallback playback error:', e);
                                            setError('Failed to play audio');
                                        });
                                        return;
                                    }
                                    audioQueue.current.push(buffer);
                                    console.log('Audio buffer queued, size:', buffer.byteLength);
                                    playAudioQueue();
                                } catch (err) {
                                    console.error('Audio processing error:', err.message);
                                    setError('Failed to process audio, using fallback WAV');
                                    const audioBytes = Uint8Array.from(atob(data.audio_event.audio_base_64), c => c.charCodeAt(0));
                                    const wavBlob = createWavBlob(audioBytes);
                                    const url = URL.createObjectURL(wavBlob);
                                    const audio = new Audio(url);
                                    audio.play().then(() => {
                                        console.log('Fallback WAV playback started');
                                        audio.onended = () => {
                                            console.log('Fallback WAV playback ended');
                                            URL.revokeObjectURL(url);
                                            isPlaying.current = false;
                                            playAudioQueue();
                                        };
                                    }).catch(e => {
                                        console.error('Fallback playback error:', e);
                                        setError('Failed to play audio');
                                    });
                                }
                            } else if (data.type === 'error') {
                                console.error('Server error:', data.error);
                                setError(`Server error: ${data.error.message || 'Unknown error'}`);
                            } else if (data.type === 'user_transcription_event' && data.user_transcription_event?.user_transcript) {
                                console.log('Server received user transcript:', data.user_transcription_event.user_transcript);
                                lastTranscriptionTime.current = Date.now();
                                retryQueue.current = []; // Clear retry queue
                            } else {
                                console.log('Unhandled message type:', data.type);
                            }
                        } catch (err) {
                            console.error('JSON parse error:', err.message);
                            setError('Failed to parse server response');
                        }
                    } else {
                        console.error('Received unexpected binary data');
                        setError('Received invalid data from server');
                    }
                };

                websocketRef.current.onerror = (err) => {
                    console.error('WebSocket error:', err);
                    setError('Connection error. Attempting to reconnect...');
                };

                websocketRef.current.onclose = (event) => {
                    console.log('WebSocket closed, code:', event.code, 'reason:', event.reason || 'No reason provided');
                    setIsConnected(false);
                    setStatus('Disconnected');
                    stopMicrophone();
                    if (pingIntervalRef.current) {
                        clearInterval(pingIntervalRef.current);
                        pingIntervalRef.current = null;
                    }
                    if (isOnCall && reconnectAttempts.current < maxReconnectAttempts) {
                        reconnectAttempts.current += 1;
                        console.log(`Reconnecting WebSocket, attempt ${reconnectAttempts.current}/${maxReconnectAttempts}`);
                        setTimeout(connectWebSocket, 2000 * reconnectAttempts.current);
                    }
                };
            };

            const startMicrophone = async () => {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true } });
                    mediaStreamRef.current = stream;
                    const source = audioContext.current.createMediaStreamSource(stream);
                    scriptProcessorRef.current = audioContext.current.createScriptProcessor(4096, 1, 1);
                    source.connect(scriptProcessorRef.current);
                    scriptProcessorRef.current.onaudioprocess = (e) => {
                        if (websocketRef.current && websocketRef.current.readyState === WebSocket.OPEN) {
                            const input = e.inputBuffer.getChannelData(0);
                            const buffer = new ArrayBuffer(input.length * 2);
                            const view = new DataView(buffer);
                            for (let i = 0; i < input.length; i++) {
                                const s = Math.max(-1, Math.min(1, input[i]));
                                view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                            }
                            // Log first 10 samples for debugging
                            const floatArray = new Float32Array(Math.min(10, input.length));
                            for (let i = 0; i < floatArray.length; i++) {
                                floatArray[i] = input[i];
                            }
                            console.log('User audio samples (first 10):', floatArray);
                            const base64 = arrayBufferToBase64(buffer);
                            console.log('Sending user audio chunk, size:', buffer.byteLength);
                            websocketRef.current.send(JSON.stringify({ type: 'user_audio_chunk', user_audio_chunk: base64 }));
                        }
                    };
                    console.log('Microphone streaming started (PCM 16000Hz)');
                    setStatus('Listening...');
                    if (recognitionRef.current) recognitionRef.current.start();
                } catch (err) {
                    console.error('Mic error:', err);
                    setError('Microphone permission denied.');
                }
            };

            const stopMicrophone = () => {
                if (mediaStreamRef.current) {
                    mediaStreamRef.current.getTracks().forEach(track => track.stop());
                    mediaStreamRef.current = null;
                }
                if (scriptProcessorRef.current) {
                    scriptProcessorRef.current.disconnect();
                    scriptProcessorRef.current = null;
                }
                if (recognitionRef.current) recognitionRef.current.stop();
                console.log('Microphone stopped');
            };

            function arrayBufferToBase64(buffer) {
                let binary = '';
                const bytes = new Uint8Array(buffer);
                const len = bytes.byteLength;
                for (let i = 0; i < len; i++) {
                    binary += String.fromCharCode(bytes[i]);
                }
                return window.btoa(binary);
            }

            const endCall = () => {
                if (websocketRef.current) websocketRef.current.close();
                stopMicrophone();
                setIsOnCall(false);
                setCurrentPage('intro');
                setCallTranscript([]);
                setStatus('Amaia is online');
                setError(null);
                audioQueue.current = [];
                isPlaying.current = false;
                responseBuffer.current = '';
                lastResponse.current = '';
                lastUserInput.current = '';
                retryQueue.current = [];
                if (pingIntervalRef.current) {
                    clearInterval(pingIntervalRef.current);
                    pingIntervalRef.current = null;
                }
            };

            // INTRO PAGE
            if (currentPage === 'intro') {
                return (
                    <div style={{ minHeight: '100vh', background: '#000', color: '#fff', display: 'flex', alignItems: 'center', justifyContent: 'center', position: 'relative', overflow: 'hidden' }}>
                        <div style={{ position: 'absolute', inset: 0, opacity: 0.2 }}>
                            <div style={{ position: 'absolute', top: '80px', left: '40px', width: '384px', height: '384px', background: '#ec4899', borderRadius: '9999px', filter: 'blur(80px)' }} className="animate-pulse" />
                            <div style={{ position: 'absolute', bottom: '80px', right: '40px', width: '320px', height: '320px', background: '#a855f7', borderRadius: '9999px', filter: 'blur(80px)', animationDelay: '1s' }} className="animate-pulse" />
                        </div>

                        <div style={{ position: 'relative', zIndex: 10, maxWidth: '448px', padding: '24px', display: 'flex', flexDirection: 'column', gap: '32px', textAlign: 'center' }}>
                            <div style={{ display: 'flex', flexDirection: 'column', gap: '24px' }}>
                                <div style={{ width: '96px', height: '96px', margin: '0 auto', borderRadius: '9999px', background: 'linear-gradient(135deg, #ec4899, #a855f7)', boxShadow: '0 0 50px rgba(236, 72, 153, 0.5)' }} className="animate-pulse" />
                                <div>
                                    <h1 style={{ fontSize: '48px', fontWeight: 300, letterSpacing: '0.1em', marginBottom: '8px' }}>Amaia</h1>
                                    <p style={{ color: '#9ca3af', fontSize: '14px' }}>is calling...</p>
                                </div>
                            </div>

                            <div style={{ display: 'flex', alignItems: 'center', justifyContent: 'center', gap: '8px' }}>
                                <div style={{ width: '8px', height: '8px', background: '#4ade80', borderRadius: '9999px' }} className="animate-pulse" />
                                <p style={{ fontSize: '12px', color: '#9ca3af' }}>live voice call</p>
                            </div>

                            <div style={{ display: 'flex', gap: '16px', justifyContent: 'center' }}>
                                <button onClick={startCall} style={{ padding: '16px 48px', background: '#16a34a', color: '#fff', border: 'none', borderRadius: '9999px', fontWeight: '600', cursor: 'pointer', fontSize: '16px', boxShadow: '0 0 20px rgba(22, 163, 74, 0.5)' }}>
                                    ðŸ“ž Answer
                                </button>
                            </div>

                            <p style={{ fontSize: '12px', color: '#4b5563', marginTop: '32px' }}>
                                Welcome to Amaia's world. Real voice conversation powered by ElevenLabs agent.
                            </p>
                            {error && <p style={{ color: '#dc2626', fontSize: '14px', fontWeight: 500 }}>{error}</p>}
                        </div>
                    </div>
                );
            }

            // CALL PAGE
            if (currentPage === 'call') {
                return (
                    <div style={{ minHeight: '100vh', background: 'linear-gradient(to bottom, #030712, #000)', color: '#fff', display: 'flex', flexDirection: 'column' }}>
                        <div style={{ position: 'sticky', top: 0, zIndex: 40, background: 'rgba(0, 0, 0, 0.8)', backdropFilter: 'blur(12px)', borderBottom: '1px solid #1f2937' }}>
                            <div style={{ maxWidth: '1024px', margin: '0 auto', padding: '0 16px', height: '64px', display: 'flex', alignItems: 'center', justifyContent: 'space-between' }}>
                                <div style={{ textAlign: 'center', flex: 1 }}>
                                    <h2 style={{ fontWeight: 600 }}>Amaia</h2>
                                    <p style={{ fontSize: '12px', color: '#4ade80' }}>{isConnected ? 'on call' : 'connecting...'}</p>
                                </div>
                                <button onClick={endCall} style={{ background: '#dc2626', border: 'none', borderRadius: '9999px', padding: '12px', color: '#fff', cursor: 'pointer', fontSize: '20px' }}>
                                    ðŸ“ž
                                </button>
                            </div>
                        </div>

                        <div style={{ flex: 1, display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center', padding: '32px 16px', gap: '48px' }}>
                            <div style={{ position: 'relative' }}>
                                <div style={{ width: '128px', height: '128px', borderRadius: '9999px', background: 'linear-gradient(135deg, #ec4899, #a855f7)', boxShadow: '0 0 50px rgba(236, 72, 153, 0.5)', display: 'flex', alignItems: 'center', justifyContent: 'center', fontSize: '32px' }} className={isConnected ? 'animate-pulse' : ''}>
                                    ðŸŽ¤
                                </div>
                            </div>

                            <div style={{ textAlign: 'center' }}>
                                <p style={{ color: '#9ca3af', fontSize: '14px' }}>{status}</p>
                                {error && <p style={{ color: '#dc2626', fontSize: '14px', fontWeight: 500 }}>{error}</p>}
                            </div>

                            <div style={{ maxWidth: '448px', display: 'flex', flexDirection: 'column', gap: '12px', maxHeight: '200px', overflowY: 'auto' }}>
                                {callTranscript.map((msg, i) => (
                                    <div key={i} style={{ fontSize: '14px', color: msg.speaker === 'You' ? '#fda4af' : '#d1d5db' }}>
                                        <p style={{ fontSize: '12px', color: '#4b5563', marginBottom: '4px' }}>{msg.speaker} ({msg.time})</p>
                                        <p>{msg.text}</p>
                                    </div>
                                ))}
                            </div>
                        </div>

                        <div style={{ background: 'rgba(0, 0, 0, 0.5)', borderTop: '1px solid #1f2937', padding: '24px 16px', maxHeight: '192px', overflowY: 'auto' }}>
                            <p style={{ fontSize: '12px', color: '#4b5563', textTransform: 'uppercase', letterSpacing: '0.05em', marginBottom: '16px' }}>Call History</p>
                            <div style={{ display: 'flex', flexDirection: 'column', gap: '12px' }}>
                                {callTranscript.map((msg, i) => (
                                    <div key={i} style={{ fontSize: '12px', color: msg.speaker === 'You' ? '#fda4af' : '#9ca3af' }}>
                                        <p style={{ fontWeight: 600, marginBottom: '4px' }}>{msg.speaker} ({msg.time})</p>
                                        <p>{msg.text}</p>
                                    </div>
                                ))}
                            </div>
                        </div>
                    </div>
                );
            }
        }

        ReactDOM.render(<AmaiaPlatform />, document.getElementById('root'));
    </script>
</body>
</html>
